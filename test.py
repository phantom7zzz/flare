#!/usr/bin/env python3
"""
æµ‹è¯•FLAREæœªæ¥è§‚æµ‹åŠŸèƒ½ - ä¿®å¤ç‰ˆ
"""

import os
import sys
import yaml
import torch
import numpy as np
from pathlib import Path
import glob

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_file = Path(__file__)
project_root = current_file.parent
sys.path.append(str(project_root))

def find_actual_data_path():
    """è‡ªåŠ¨æŸ¥æ‰¾å®é™…çš„æ•°æ®è·¯å¾„"""
    possible_paths = [
        "training_data",
        "processed_data", 
        "data/datasets",
        "../data",
        "../../data",
    ]
    
    for base_path in possible_paths:
        if os.path.exists(base_path):
            # æŸ¥æ‰¾åŒ…å«.hdf5æ–‡ä»¶çš„å­ç›®å½•
            for root, dirs, files in os.walk(base_path):
                hdf5_files = [f for f in files if f.endswith('.hdf5')]
                if hdf5_files:
                    print(f"ğŸ” æ‰¾åˆ°æ•°æ®è·¯å¾„: {root}, åŒ…å« {len(hdf5_files)} ä¸ªHDF5æ–‡ä»¶")
                    return root
    
    return None

def create_test_config_with_real_path():
    """åˆ›å»ºä½¿ç”¨çœŸå®æ•°æ®è·¯å¾„çš„æµ‹è¯•é…ç½®"""
    data_path = find_actual_data_path()
    
    if data_path is None:
        print("âŒ æœªæ‰¾åˆ°åŒ…å«HDF5æ–‡ä»¶çš„æ•°æ®è·¯å¾„")
        print("ğŸ’¡ è¯·ç¡®ä¿ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€å­˜åœ¨å¹¶åŒ…å«.hdf5æ–‡ä»¶:")
        print("   - training_data/")
        print("   - processed_data/")
        print("   - data/datasets/") 
        print("   - ../data/")
        return None
    
    test_config_path = "model_config/test_future_obs.yml"
    os.makedirs("model_config", exist_ok=True)
    
    test_config = {
        "data_path": data_path,
    }
    
    with open(test_config_path, "w") as f:
        yaml.dump(test_config, f)
    
    print(f"ğŸ“ åˆ›å»ºæµ‹è¯•é…ç½®: {test_config_path}")
    print(f"ğŸ“ æ•°æ®è·¯å¾„: {data_path}")
    
    return test_config_path

def test_hdf5_future_obs():
    """æµ‹è¯•HDF5æ•°æ®é›†çš„æœªæ¥è§‚æµ‹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•HDF5æœªæ¥è§‚æµ‹åŠŸèƒ½...")
    
    try:
        from data.hdf5_vla_dataset import HDF5VLADataset
        
        # åˆ›å»ºä½¿ç”¨çœŸå®è·¯å¾„çš„æµ‹è¯•é…ç½®
        test_config_path = create_test_config_with_real_path()
        if test_config_path is None:
            return False
        
        # åˆå§‹åŒ–æ•°æ®é›†
        dataset = HDF5VLADataset(test_config_path)
        print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–æˆåŠŸï¼ŒåŒ…å« {len(dataset)} ä¸ªepisode")
        
        if len(dataset) == 0:
            print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
            return False
        
        # æµ‹è¯•å¤šä¸ªæ ·æœ¬
        success_count = 0
        total_tests = min(3, len(dataset))  # å‡å°‘æµ‹è¯•æ•°é‡
        
        for i in range(total_tests):
            print(f"\nğŸ” æµ‹è¯•æ ·æœ¬ {i+1}/{total_tests}")
            
            try:
                sample = dataset.get_item(index=i)
                
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                required_fields = [
                    "meta", "state", "actions", "state_indicator",
                    "cam_high", "cam_high_mask",
                    "future_obs_frame", "future_obs_mask", "future_step_id"
                ]
                
                missing_fields = [field for field in required_fields if field not in sample]
                if missing_fields:
                    print(f"âŒ ç¼ºå¤±å­—æ®µ: {missing_fields}")
                    continue
                
                # æ£€æŸ¥æœªæ¥è§‚æµ‹
                future_frame = sample["future_obs_frame"]
                future_mask = sample["future_obs_mask"]
                future_step = sample["future_step_id"]
                current_step = sample["meta"]["step_id"]
                
                print(f"   å½“å‰æ­¥éª¤: {current_step}")
                print(f"   æœªæ¥æ­¥éª¤: {future_step}")
                print(f"   æœªæ¥è§‚æµ‹æœ‰æ•ˆ: {future_mask}")
                
                if future_frame is not None:
                    print(f"   æœªæ¥è§‚æµ‹å½¢çŠ¶: {future_frame.shape}")
                    print(f"   æœªæ¥è§‚æµ‹æ•°æ®ç±»å‹: {future_frame.dtype}")
                    print(f"   æœªæ¥è§‚æµ‹å€¼èŒƒå›´: [{future_frame.min()}, {future_frame.max()}]")
                    
                    # éªŒè¯æœªæ¥è§‚æµ‹çš„è®¡ç®—é€»è¾‘
                    with open("configs/base.yaml", "r") as f:
                        config = yaml.safe_load(f)
                    action_chunk_size = config["common"]["action_chunk_size"]
                    expected_future_step = current_step + action_chunk_size - 1
                    
                    print(f"   é¢„æœŸæœªæ¥æ­¥éª¤: {expected_future_step}")
                    print(f"   å®é™…æœªæ¥æ­¥éª¤: {future_step}")
                    
                    if future_step == expected_future_step or future_step == sample["meta"]["#steps"] - 1:
                        print(f"   âœ… æœªæ¥è§‚æµ‹è®¡ç®—æ­£ç¡®")
                        success_count += 1
                    else:
                        print(f"   âŒ æœªæ¥è§‚æµ‹è®¡ç®—é”™è¯¯")
                        
                else:
                    print(f"   âŒ æœªæ¥è§‚æµ‹å¸§ä¸ºç©º")
                    
            except Exception as e:
                print(f"   ğŸ’¥ æ ·æœ¬ {i} æµ‹è¯•å¤±è´¥: {e}")
                continue
        
        print(f"\nğŸ“Š HDF5æµ‹è¯•ç»“æœ: {success_count}/{total_tests} æˆåŠŸ")
        return success_count > 0  # è‡³å°‘ä¸€ä¸ªæˆåŠŸå³å¯
        
    except Exception as e:
        print(f"âŒ HDF5æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_train_dataset_future_obs():
    """æµ‹è¯•è®­ç»ƒæ•°æ®é›†çš„æœªæ¥è§‚æµ‹åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•è®­ç»ƒæ•°æ®é›†æœªæ¥è§‚æµ‹åŠŸèƒ½...")
    
    try:
        from train.dataset import VLAConsumerDatasetWithFLARE
        from models.multimodal_encoder.siglip_encoder import SiglipVisionTower
        
        # é¦–å…ˆç¡®ä¿æµ‹è¯•é…ç½®å­˜åœ¨ä¸”è·¯å¾„æ­£ç¡®
        test_config_path = "model_config/test_future_obs.yml"
        if not os.path.exists(test_config_path):
            test_config_path = create_test_config_with_real_path()
            if test_config_path is None:
                print("âŒ æ— æ³•åˆ›å»ºæœ‰æ•ˆçš„æµ‹è¯•é…ç½®")
                return False
        
        # éªŒè¯é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®è·¯å¾„
        with open(test_config_path, "r") as f:
            test_config = yaml.safe_load(f)
        
        data_path = test_config["data_path"]
        if not os.path.exists(data_path):
            print(f"âŒ é…ç½®çš„æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰HDF5æ–‡ä»¶
        hdf5_files = glob.glob(os.path.join(data_path, "**", "*.hdf5"), recursive=True)
        if not hdf5_files:
            print(f"âŒ æ•°æ®è·¯å¾„ä¸­æ²¡æœ‰æ‰¾åˆ°HDF5æ–‡ä»¶: {data_path}")
            return False
        
        print(f"âœ… æ•°æ®è·¯å¾„éªŒè¯é€šè¿‡: {data_path}")
        print(f"ğŸ“ æ‰¾åˆ° {len(hdf5_files)} ä¸ªHDF5æ–‡ä»¶")
        
        # åŠ è½½é…ç½®
        with open("configs/base.yaml", "r") as f:
            config = yaml.safe_load(f)
        
        # åˆ›å»ºè§†è§‰ç¼–ç å™¨ï¼ˆä½¿ç”¨æœ¬åœ°è·¯å¾„é¿å…ç½‘ç»œé—®é¢˜ï¼‰
        try:
            vision_encoder = SiglipVisionTower(
                vision_tower="google/siglip-so400m-patch14-384",  # æˆ–ä½¿ç”¨æœ¬åœ°è·¯å¾„
                args=None
            )
            image_processor = vision_encoder.image_processor
        except Exception as e:
            print(f"âš ï¸  è§†è§‰ç¼–ç å™¨åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨mockå¤„ç†å™¨: {e}")
            # åˆ›å»ºmock image processor
            class MockImageProcessor:
                def __init__(self):
                    self.image_mean = [0.485, 0.456, 0.406]
                    self.size = {"height": 224, "width": 224}
                
                def preprocess(self, image, return_tensors="pt"):
                    import torchvision.transforms as transforms
                    transform = transforms.Compose([
                        transforms.Resize((224, 224)),
                        transforms.ToTensor(),
                    ])
                    return {"pixel_values": [transform(image)]}
            
            image_processor = MockImageProcessor()
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = VLAConsumerDatasetWithFLARE(
            model_config_path=test_config_path,
            config=config["dataset"],
            tokenizer=None,  # ç®€åŒ–æµ‹è¯•
            image_processor=image_processor,
            num_cameras=config["common"]["num_cameras"],
            img_history_size=config["common"]["img_history_size"],
            dataset_type="finetune",
            image_aug=False,
            use_hdf5=True,  # ä½¿ç”¨HDF5
            use_precomp_lang_embed=True,
            # FLAREå‚æ•°
            enable_future_obs=True,
            future_obs_prob=1.0,  # 100%ä½¿ç”¨æœªæ¥è§‚æµ‹è¿›è¡Œæµ‹è¯•
            action_chunk_size=config["common"]["action_chunk_size"],
        )
        
        print(f"âœ… è®­ç»ƒæ•°æ®é›†åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ“Š æ•°æ®é›†é•¿åº¦: {len(dataset)}")
        
        if len(dataset) == 0:
            print("âŒ è®­ç»ƒæ•°æ®é›†é•¿åº¦ä¸º0")
            return False
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        success_count = 0
        total_tests = min(2, len(dataset))  # å‡å°‘æµ‹è¯•æ•°é‡é¿å…è¿‡é•¿
        
        for i in range(total_tests):
            print(f"\nğŸ” æµ‹è¯•è®­ç»ƒæ ·æœ¬ {i+1}/{total_tests}")
            
            try:
                sample = dataset[i]
                
                # æ£€æŸ¥å…³é”®å­—æ®µ
                has_future_obs = sample.get("has_future_obs", False)
                future_obs_image = sample.get("future_obs_image")
                text_instruction = sample.get("text_instruction", "")
                
                print(f"   æ•°æ®é›†: {sample.get('dataset_name', 'Unknown')}")
                print(f"   åŒ…å«æœªæ¥è§‚æµ‹: {has_future_obs}")
                print(f"   æ–‡æœ¬æŒ‡ä»¤: {text_instruction[:50]}...")
                
                if has_future_obs and future_obs_image is not None:
                    print(f"   æœªæ¥è§‚æµ‹å›¾åƒå½¢çŠ¶: {future_obs_image.shape}")
                    print(f"   æœªæ¥è§‚æµ‹å›¾åƒç±»å‹: {type(future_obs_image)}")
                    
                    # éªŒè¯å¼ é‡æ ¼å¼
                    if isinstance(future_obs_image, torch.Tensor):
                        print(f"   å¼ é‡æ•°æ®ç±»å‹: {future_obs_image.dtype}")
                        print(f"   å¼ é‡è®¾å¤‡: {future_obs_image.device}")
                        print(f"   âœ… æœªæ¥è§‚æµ‹å¤„ç†æ­£ç¡®")
                        success_count += 1
                    else:
                        print(f"   âŒ æœªæ¥è§‚æµ‹ä¸æ˜¯å¼ é‡æ ¼å¼")
                else:
                    print(f"   âš ï¸  æœªæ¥è§‚æµ‹ä¸å¯ç”¨")
                    
            except Exception as e:
                print(f"   ğŸ’¥ è®­ç»ƒæ ·æœ¬ {i} æµ‹è¯•å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"\nğŸ“Š è®­ç»ƒæ•°æ®é›†æµ‹è¯•ç»“æœ: {success_count}/{total_tests} æˆåŠŸ")
        return success_count > 0  # è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸ
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_collator_future_obs():
    """æµ‹è¯•æ•°æ®æ”¶é›†å™¨çš„æœªæ¥è§‚æµ‹å¤„ç†"""
    print("\nğŸ§ª æµ‹è¯•æ•°æ®æ”¶é›†å™¨æœªæ¥è§‚æµ‹åŠŸèƒ½...")
    
    try:
        from train.dataset import DataCollatorForVLAConsumerDatasetWithFLARE
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        mock_instances = []
        for i in range(2):
            instance = {
                "states": torch.randn(1, 128),
                "actions": torch.randn(32, 128),
                "state_elem_mask": torch.ones(128),
                "state_norm": torch.ones(128),
                "images": [torch.randn(3, 224, 224) for _ in range(6)],
                "data_idx": 0,
                "ctrl_freq": 25,
                "text_instruction": f"æµ‹è¯•æŒ‡ä»¤ {i}",
                "has_future_obs": i == 0,  # åªæœ‰ç¬¬ä¸€ä¸ªæ ·æœ¬æœ‰æœªæ¥è§‚æµ‹
                "future_obs_image": torch.randn(3, 224, 224) if i == 0 else None,
                "lang_embed": torch.randn(50, 1024),
            }
            mock_instances.append(instance)
        
        # åˆ›å»ºæ•°æ®æ”¶é›†å™¨
        collator = DataCollatorForVLAConsumerDatasetWithFLARE(tokenizer=None)
        
        # å¤„ç†æ‰¹æ¬¡
        batch = collator(mock_instances)
        
        # éªŒè¯æ‰¹æ¬¡ç»“æ„
        required_keys = [
            "states", "actions", "state_elem_mask", "state_norm", 
            "images", "future_obs_images", "has_future_obs", "text_instructions"
        ]
        
        missing_keys = [key for key in required_keys if key not in batch]
        if missing_keys:
            print(f"âŒ æ‰¹æ¬¡ç¼ºå¤±é”®: {missing_keys}")
            return False
        
        print(f"âœ… æ‰¹æ¬¡ç»“æ„æ­£ç¡®")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch['states'].shape[0]}")
        print(f"   æœªæ¥è§‚æµ‹å½¢çŠ¶: {batch['future_obs_images'].shape}")
        print(f"   æœªæ¥è§‚æµ‹æ©ç : {batch['has_future_obs']}")
        print(f"   æ–‡æœ¬æŒ‡ä»¤: {batch['text_instructions']}")
        
        # éªŒè¯æœªæ¥è§‚æµ‹å¤„ç†
        has_future_obs = batch['has_future_obs']
        expected_mask = torch.tensor([True, False])
        
        if torch.equal(has_future_obs, expected_mask):
            print(f"âœ… æœªæ¥è§‚æµ‹æ©ç æ­£ç¡®")
            return True
        else:
            print(f"âŒ æœªæ¥è§‚æµ‹æ©ç é”™è¯¯: æœŸæœ› {expected_mask}, å®é™… {has_future_obs}")
            return False
            
    except Exception as e:
        print(f"âŒ æ•°æ®æ”¶é›†å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹FLAREæœªæ¥è§‚æµ‹åŠŸèƒ½æµ‹è¯• (ä¿®å¤ç‰ˆ)")
    print("=" * 60)
    
    tests = [
        ("HDF5æœªæ¥è§‚æµ‹", test_hdf5_future_obs),
        ("è®­ç»ƒæ•°æ®é›†æœªæ¥è§‚æµ‹", test_train_dataset_future_obs),
        ("æ•°æ®æ”¶é›†å™¨æœªæ¥è§‚æµ‹", test_data_collator_future_obs),
    ]
    
    passed = 0
    total = len(tests)
    results = []
    
    for test_name, test_func in tests:
        print(f"\nğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
        try:
            if test_func():
                passed += 1
                results.append(f"âœ… {test_name}")
            else:
                results.append(f"âŒ {test_name}")
        except Exception as e:
            print(f"ğŸ’¥ æµ‹è¯• {test_name} å‡ºç°å¼‚å¸¸: {e}")
            results.append(f"ğŸ’¥ {test_name}: {str(e)[:50]}...")
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æœªæ¥è§‚æµ‹æµ‹è¯•ç»“æœæ±‡æ€»:")
    for result in results:
        print(f"  {result}")
    
    print(f"\nğŸ“ˆ æ€»ä½“ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("\nğŸŠ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æœªæ¥è§‚æµ‹åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
        print("\nğŸ”§ ä¿®å¤è¦ç‚¹:")
        print("âœ… HDF5æ•°æ®é›†æ”¯æŒæœªæ¥è§‚æµ‹è®¡ç®—")
        print("âœ… è®­ç»ƒæ•°æ®é›†æ­£ç¡®å¤„ç†æœªæ¥è§‚æµ‹")
        print("âœ… æ•°æ®æ”¶é›†å™¨æ­£ç¡®æ‰¹å¤„ç†æœªæ¥è§‚æµ‹")
        print("\nğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹FLAREè®­ç»ƒäº†ï¼")
        
        # æ˜¾ç¤ºè®­ç»ƒå‘½ä»¤
        print("\nğŸ¯ å¼€å§‹FLAREè®­ç»ƒ:")
        print("bash scripts/train_flare.sh <CONFIG_NAME>")
        
    elif passed >= total * 0.7:  # 70%ä»¥ä¸Šé€šè¿‡
        print("\nğŸ”¶ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥å°è¯•è®­ç»ƒ")
        print("âš ï¸  æ³¨æ„è§‚å¯Ÿå¤±è´¥çš„ç»„ä»¶")
        
        # æä¾›å…·ä½“çš„ä¿®å¤å»ºè®®
        if passed == 2:  # åªæœ‰è®­ç»ƒæ•°æ®é›†å¤±è´¥
            print("\nğŸ’¡ è®­ç»ƒæ•°æ®é›†é—®é¢˜ä¿®å¤å»ºè®®:")
            print("1. æ£€æŸ¥ model_config/test_future_obs.yml ä¸­çš„data_path")
            print("2. ç¡®ä¿æ•°æ®è·¯å¾„åŒ…å«æœ‰æ•ˆçš„.hdf5æ–‡ä»¶")
            print("3. éªŒè¯configs/base.yamlé…ç½®æ­£ç¡®")
    else:
        print("\nâŒ å¤šé¡¹æµ‹è¯•å¤±è´¥ï¼Œè¯·å…ˆä¿®å¤å…³é”®é—®é¢˜")
        print("\nğŸ”§ å¸¸è§é—®é¢˜æ’æŸ¥:")
        print("1. æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("2. HDF5æ–‡ä»¶æ˜¯å¦åŒ…å«æ‰€éœ€çš„è§‚æµ‹æ•°æ®")
        print("3. configs/base.yamlé…ç½®æ˜¯å¦æ­£ç¡®")
        print("4. ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…")
    
    print("=" * 60)
    return passed >= total * 0.7


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)